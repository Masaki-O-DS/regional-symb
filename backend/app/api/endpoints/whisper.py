import os
import shutil
import uuid
from fastapi import APIRouter, UploadFile, File, HTTPException
from openai import OpenAI
import whisper

router = APIRouter()

# whisper load

try:
    whisper_model =whisper.load_model("medium")
except  Exception as e: # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«ã‚¨ãƒ©ãƒ¼ã®å†…å®¹ã‚’eå¤‰æ•°ã«æ ¼ç´
    print(f"Whispermodelã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚:{e}")
    whisper_model = None

try:
    # ğŸ”½ "OPENAI_API_KEY" ã¨ã„ã†åå‰ã®ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
except Exception as e:
    print(f"OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚:{e}")
    client = None

#APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å®šç¾©
@router.post("/process-audio/")
async def process_audio_and_summarize(audio_file: UploadFile = File(...)):
    if not whisper_model or not client:
        raise HTTPException(status_code=500, detail="ã‚µãƒ¼ãƒãƒ¼ã®AIãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # temp_audiotã¨ã„ã†åå‰ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€ãã“ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åã§ä¿å­˜
    temp_dir = "./temp_audio"
    os.makedirs(temp_dir, exist_ok=True)
    file_path = os.path.join(temp_dir,f"{uuid.uuid4()}.m4a")
    
    try:
        # file_path ã§æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿ç”¨ã«é–‹ã„ã¦ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ä¸­ã§ã¯ buffer ã¨ã„ã†åå‰ã§æ‰±ã†ã€‚audio_fileã®ä¸­èº«ã‚’bufferã«æ›¸ãè¾¼ã¿
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(audio_file.file,buffer)
        
        #éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã€‚verboseã¯é€”ä¸­çµŒéã®å‡ºåŠ›ã€fp16ã¯è¨ˆç®—æ–¹æ³•ã®è¨­å®š
        result = whisper_model.transcribe(file_path,verbose=True,fp16=False,language="ja")
        #è¾æ›¸å‹ã§å‡ºåŠ›ã•ã‚ŒãŸçµæœã‚’æ ¼ç´
        original_text = result["text"]
    
        if not original_text:
            raise HTTPException(status_code=400,detail="éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºå‡ºæ¥ã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        correction_response = client.chat.completions.create(
            model="gpt-4o",  # â˜…â˜…â˜… ã“ã“ã«ã‚«ãƒ³ãƒã‚’è¿½åŠ ã—ãŸã‚ˆï¼ â˜…â˜…â˜…
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ–‡ç« ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": f"ä»¥ä¸‹ã®æ–‡ç« ã§æ—¥æœ¬èªã¨ã—ã¦ãŠã‹ã—ã„éƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã«ã—ã¦ãã ã•ã„ã€‚:\n\n{original_text}"}
            ],
            temperature=0.2,
        )
        #correction_responseå†…ã®choicesã®0ç•ªç›®ã‚’æŒ‡å®šã€‚messageå†…ã«ã¯roleï¼ˆå½¹å‰²ï¼‰ã¨content(æœ¬æ–‡)ãŒæ ¼ç´ã•ã‚Œã¦ã‚‹ã€‚ãã®contentã‚’å–ã‚Šå‡ºã—ã¦å¤‰æ•°ã«æ ¼ç´ã€‚
        corrected_text = correction_response.choices[0].message.content
        
        summary_response = client.chat.completions.create(
            model = "gpt-4o",
            messages=[
                {"role":"system","content": "ã‚ãªãŸã¯æ–‡ç« è¦ç´„ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": f"ä»¥ä¸‹ã®æ–‡ç« ã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«ç®‡æ¡æ›¸ãã§è¦ç´„ã—ã¦ãã ã•ã„:\n\n{corrected_text}"}
            ],
            temperature=0.0,
        )
        summary_text = summary_response.choices[0].message.content
        
        return{
            "full_text":corrected_text,
            "summary": summary_text
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{str(e)}")
    
    finally:
        if os.path.exists(file_path):
            os.remove(file_path)